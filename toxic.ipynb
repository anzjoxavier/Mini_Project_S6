{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import xgboost\n",
    "import eli5\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,roc_curve,roc_auc_score,auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "...                  ...                                                ...   \n",
       "159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n",
       "159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n",
       "159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n",
       "159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n",
       "159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0           0             0        0       0       0              0  \n",
       "1           0             0        0       0       0              0  \n",
       "2           0             0        0       0       0              0  \n",
       "3           0             0        0       0       0              0  \n",
       "4           0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "159566      0             0        0       0       0              0  \n",
       "159567      0             0        0       0       0              0  \n",
       "159568      0             0        0       0       0              0  \n",
       "159569      0             0        0       0       0              0  \n",
       "159570      0             0        0       0       0              0  \n",
       "\n",
       "[159571 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(r'E:/ANZ JO/Mini Project/Sarcasm Analyser/toxicity.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>fffcd0960ee309b5</td>\n",
       "      <td>. \\n i totally agree, this stuff is nothing bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>fffd7a9a6eb32c16</td>\n",
       "      <td>== Throw from out field to home plate. == \\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>fffda9e8d6fafa9e</td>\n",
       "      <td>\" \\n\\n == Okinotorishima categories == \\n\\n I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>fffe8f1340a79fc2</td>\n",
       "      <td>\" \\n\\n == \"\"One of the founding nations of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>ffffce3fb183ee80</td>\n",
       "      <td>\" \\n :::Stop already. Your bullshit is not wel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153164 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text\n",
       "0       00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1       0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2       00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3       00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4       00017695ad8997eb          I don't anonymously edit articles at all.\n",
       "...                  ...                                                ...\n",
       "153159  fffcd0960ee309b5  . \\n i totally agree, this stuff is nothing bu...\n",
       "153160  fffd7a9a6eb32c16  == Throw from out field to home plate. == \\n\\n...\n",
       "153161  fffda9e8d6fafa9e  \" \\n\\n == Okinotorishima categories == \\n\\n I ...\n",
       "153162  fffe8f1340a79fc2  \" \\n\\n == \"\"One of the founding nations of the...\n",
       "153163  ffffce3fb183ee80  \" \\n :::Stop already. Your bullshit is not wel...\n",
       "\n",
       "[153164 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(r'E:/ANZ JO/Mini Project/Sarcasm Analyser/toxicity2.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_31332\\2566899487.py:1: FutureWarning: The default value of numeric_only in DataFrame.skew is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  train_df.skew()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "toxic             2.745854\n",
       "severe_toxic      9.851722\n",
       "obscene           3.992817\n",
       "threat           18.189001\n",
       "insult            4.160540\n",
       "identity_hate    10.515923\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_31332\\2705249357.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_df['comment_text'] = train_df['comment_text'].str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$','emailaddress')\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_31332\\2705249357.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_df['comment_text'] = train_df['comment_text'].str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$','webaddress')\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_31332\\2705249357.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_df['comment_text'] = train_df['comment_text'].str.replace(r'£|\\$', 'dollers')\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_31332\\2705249357.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_df['comment_text'] = train_df['comment_text'].str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$','phonenumber')\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_31332\\2705249357.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_df['comment_text'] = train_df['comment_text'].str.replace(r'\\d+(\\.\\d+)?', 'number')\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_31332\\2705249357.py:16: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_df['comment_text'] = train_df['comment_text'].str.replace(r'[^\\w\\d\\s]', ' ')\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_31332\\2705249357.py:19: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_df['comment_text'] = train_df['comment_text'].str.replace(r'\\s+', ' ')\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_31332\\2705249357.py:22: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_df['comment_text'] = train_df['comment_text'].str.replace(r'^\\s+|\\s+?$', '')\n"
     ]
    }
   ],
   "source": [
    "# Replace email addresses with 'email'\n",
    "train_df['comment_text'] = train_df['comment_text'].str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$','emailaddress')\n",
    "\n",
    "# Replace URLs with 'webaddress'\n",
    "train_df['comment_text'] = train_df['comment_text'].str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$','webaddress')\n",
    "\n",
    "# Replace money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\n",
    "train_df['comment_text'] = train_df['comment_text'].str.replace(r'£|\\$', 'dollers')\n",
    "    \n",
    "# Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
    "train_df['comment_text'] = train_df['comment_text'].str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$','phonenumber')\n",
    "   \n",
    "# Replace numbers with 'number'\n",
    "train_df['comment_text'] = train_df['comment_text'].str.replace(r'\\d+(\\.\\d+)?', 'number')\n",
    "# Remove punctuation\n",
    "train_df['comment_text'] = train_df['comment_text'].str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "# Replace whitespace between terms with a single space\n",
    "train_df['comment_text'] = train_df['comment_text'].str.replace(r'\\s+', ' ')\n",
    "\n",
    "# Remove leading and trailing whitespace\n",
    "train_df['comment_text'] = train_df['comment_text'].str.replace(r'^\\s+|\\s+?$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_31332\\2135906341.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_df['comment_text'] = test_df['comment_text'].str.replace(r'^\\s+/\\s+?$' , '')\n"
     ]
    }
   ],
   "source": [
    "test_df['comment_text'] = test_df['comment_text'].str.replace(r'^\\s+/\\s+?$' , '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m test_df[\u001b[39m'\u001b[39m\u001b[39mcomment_text\u001b[39m\u001b[39m'\u001b[39m][i]\u001b[39m.\u001b[39msplit():\n\u001b[0;32m      7\u001b[0m     j\u001b[39m.\u001b[39mappend(lemmatizer\u001b[39m.\u001b[39mlemmatize(word, pos\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mv\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m----> 8\u001b[0m     test_df[\u001b[39m'\u001b[39;49m\u001b[39mcomment_text\u001b[39;49m\u001b[39m'\u001b[39;49m][i] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(j)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\series.py:1095\u001b[0m, in \u001b[0;36mSeries.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1093\u001b[0m check_deprecated_indexers(key)\n\u001b[0;32m   1094\u001b[0m key \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m)\n\u001b[1;32m-> 1095\u001b[0m cacher_needs_updating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_is_chained_assignment_possible()\n\u001b[0;32m   1097\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mis\u001b[39;00m \u001b[39mEllipsis\u001b[39m:\n\u001b[0;32m   1098\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mslice\u001b[39m(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\series.py:1284\u001b[0m, in \u001b[0;36mSeries._check_is_chained_assignment_possible\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_view \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_cached:\n\u001b[0;32m   1283\u001b[0m     ref \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_cacher()\n\u001b[1;32m-> 1284\u001b[0m     \u001b[39mif\u001b[39;00m ref \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m ref\u001b[39m.\u001b[39;49m_is_mixed_type:\n\u001b[0;32m   1285\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_setitem_copy(t\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreferent\u001b[39m\u001b[39m\"\u001b[39m, force\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1286\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\generic.py:6007\u001b[0m, in \u001b[0;36mNDFrame._is_mixed_type\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   6002\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39many_extension_types:\n\u001b[0;32m   6003\u001b[0m     \u001b[39m# Even if they have the same dtype, we can't consolidate them,\u001b[39;00m\n\u001b[0;32m   6004\u001b[0m     \u001b[39m#  so we pretend this is \"mixed'\"\u001b[39;00m\n\u001b[0;32m   6005\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m-> 6007\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtypes\u001b[39m.\u001b[39;49mnunique() \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\base.py:1039\u001b[0m, in \u001b[0;36mIndexOpsMixin.nunique\u001b[1;34m(self, dropna)\u001b[0m\n\u001b[0;32m   1005\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnunique\u001b[39m(\u001b[39mself\u001b[39m, dropna: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m   1006\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[39m    Return number of unique elements in the object.\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[39m    4\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m     uniqs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munique()\n\u001b[0;32m   1040\u001b[0m     \u001b[39mif\u001b[39;00m dropna:\n\u001b[0;32m   1041\u001b[0m         uniqs \u001b[39m=\u001b[39m remove_na_arraylike(uniqs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\series.py:2242\u001b[0m, in \u001b[0;36mSeries.unique\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2183\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munique\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ArrayLike:\n\u001b[0;32m   2184\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2185\u001b[0m \u001b[39m    Return unique values of Series object.\u001b[39;00m\n\u001b[0;32m   2186\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2240\u001b[0m \u001b[39m    Categories (3, object): ['a' < 'b' < 'c']\u001b[39;00m\n\u001b[0;32m   2241\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2242\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49munique()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\base.py:1001\u001b[0m, in \u001b[0;36mIndexOpsMixin.unique\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    999\u001b[0m         result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(result)\n\u001b[0;32m   1000\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1001\u001b[0m     result \u001b[39m=\u001b[39m unique1d(values)\n\u001b[0;32m   1003\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\algorithms.py:409\u001b[0m, in \u001b[0;36munique\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munique\u001b[39m(values):\n\u001b[0;32m    316\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[39m    Return unique values based on a hash table.\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[39m    array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 409\u001b[0m     \u001b[39mreturn\u001b[39;00m unique_with_mask(values)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\algorithms.py:425\u001b[0m, in \u001b[0;36munique_with_mask\u001b[1;34m(values, mask)\u001b[0m\n\u001b[0;32m    423\u001b[0m table \u001b[39m=\u001b[39m htable(\u001b[39mlen\u001b[39m(values))\n\u001b[0;32m    424\u001b[0m \u001b[39mif\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 425\u001b[0m     uniques \u001b[39m=\u001b[39m table\u001b[39m.\u001b[39;49munique(values)\n\u001b[0;32m    426\u001b[0m     uniques \u001b[39m=\u001b[39m _reconstruct_data(uniques, original\u001b[39m.\u001b[39mdtype, original)\n\u001b[0;32m    427\u001b[0m     \u001b[39mreturn\u001b[39;00m uniques\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "for i in range(len(test_df['comment_text'])):\n",
    "    test_df['comment_text'][i] = test_df['comment_text'][i].lower()\n",
    "    j = []\n",
    "    for word in test_df['comment_text'][i].split():\n",
    "        j.append(lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "        test_df['comment_text'][i] = \"\".join(j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
